{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYxRkKCPO14BxvXEwhVp5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyoooo/capstondesign_voicefishing/blob/main/normaldata_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "normal_df = pd.read_csv(\"/content/drive/MyDrive/merged_normal.csv\")\n",
        "\n",
        "# 감정 분석 결과 로드\n",
        "emotion_df = pd.read_csv(\"/content/drive/MyDrive/emotion_results.csv\")\n",
        "\n",
        "# 정상 데이터 + 감정분석 merge\n",
        "merged_normal = pd.merge(normal_df, emotion_df, on='file', how='left')\n",
        "\n",
        "# label 추가\n",
        "merged_normal['label'] = 0\n",
        "\n",
        "# 저장\n",
        "merged_normal.to_csv(\"/content/drive/MyDrive/merged_normal.csv\", index=False)\n",
        "\n",
        "print(f\"✅ merged_normal 저장 완료: {merged_normal.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8h0muwB2Ezc",
        "outputId": "6ec310eb-461b-49ab-902c-5d3e853d096c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ merged_normal 저장 완료: (183, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQl9AtUkViFE",
        "outputId": "e8c0413a-82ad-42be-cf33-1ef323a59194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ json 파일 183개 발견\n",
            "✅ 정상 데이터 DataFrame 생성 완료: 183 rows\n",
            "                  file                                   transcribed_text\n",
            "0  SDRW2400000051.json  저는 최근에 보면 이런 어 투자하고 있는 그런 게 있는데 보면 주식이나 이런 거에 ...\n",
            "1  SDRW2400000107.json  저는 현재 경제 상황이 어 나쁘지도 좋다고도 생각을 안 하고 있어요. 근데 요즘 경...\n",
            "2  SDRW2400000172.json  name1 님은 최근에 하고 계신 재테크나 관심 있는 금융 서비스 같은 거 있으세요...\n",
            "3  SDRW2400000320.json  요즘 우리 나이 세대뿐만 아니고 젊은 분들이나 나이 많으신 분들이나 재테크 관련해 ...\n",
            "4  SDRW2400000357.json  현재 거주 중인 그 부동산 장단점에 대해서 우리 한번 이야기해 볼까요? 그 아 우리...\n",
            "✅ keyword flag 추가 완료\n",
            "                  file                                   transcribed_text  \\\n",
            "0  SDRW2400000051.json  저는 최근에 보면 이런 어 투자하고 있는 그런 게 있는데 보면 주식이나 이런 거에 ...   \n",
            "1  SDRW2400000107.json  저는 현재 경제 상황이 어 나쁘지도 좋다고도 생각을 안 하고 있어요. 근데 요즘 경...   \n",
            "2  SDRW2400000172.json  name1 님은 최근에 하고 계신 재테크나 관심 있는 금융 서비스 같은 거 있으세요...   \n",
            "3  SDRW2400000320.json  요즘 우리 나이 세대뿐만 아니고 젊은 분들이나 나이 많으신 분들이나 재테크 관련해 ...   \n",
            "4  SDRW2400000357.json  현재 거주 중인 그 부동산 장단점에 대해서 우리 한번 이야기해 볼까요? 그 아 우리...   \n",
            "\n",
            "   has_keyword  \n",
            "0            1  \n",
            "1            0  \n",
            "2            1  \n",
            "3            1  \n",
            "4            1  \n",
            "✅ 감정분석 merge 완료\n",
            "                  file                                   transcribed_text  \\\n",
            "0  SDRW2400000051.json  저는 최근에 보면 이런 어 투자하고 있는 그런 게 있는데 보면 주식이나 이런 거에 ...   \n",
            "1  SDRW2400000107.json  저는 현재 경제 상황이 어 나쁘지도 좋다고도 생각을 안 하고 있어요. 근데 요즘 경...   \n",
            "2  SDRW2400000172.json  name1 님은 최근에 하고 계신 재테크나 관심 있는 금융 서비스 같은 거 있으세요...   \n",
            "3  SDRW2400000320.json  요즘 우리 나이 세대뿐만 아니고 젊은 분들이나 나이 많으신 분들이나 재테크 관련해 ...   \n",
            "4  SDRW2400000357.json  현재 거주 중인 그 부동산 장단점에 대해서 우리 한번 이야기해 볼까요? 그 아 우리...   \n",
            "\n",
            "  emotion  confidence  has_keyword  \n",
            "0     NaN         NaN            1  \n",
            "1     NaN         NaN            0  \n",
            "2     NaN         NaN            1  \n",
            "3     NaN         NaN            1  \n",
            "4     NaN         NaN            1  \n",
            "✅ is_deepfake 컬럼 추가 완료\n",
            "                  file                                   transcribed_text  \\\n",
            "0  SDRW2400000051.json  저는 최근에 보면 이런 어 투자하고 있는 그런 게 있는데 보면 주식이나 이런 거에 ...   \n",
            "1  SDRW2400000107.json  저는 현재 경제 상황이 어 나쁘지도 좋다고도 생각을 안 하고 있어요. 근데 요즘 경...   \n",
            "2  SDRW2400000172.json  name1 님은 최근에 하고 계신 재테크나 관심 있는 금융 서비스 같은 거 있으세요...   \n",
            "3  SDRW2400000320.json  요즘 우리 나이 세대뿐만 아니고 젊은 분들이나 나이 많으신 분들이나 재테크 관련해 ...   \n",
            "4  SDRW2400000357.json  현재 거주 중인 그 부동산 장단점에 대해서 우리 한번 이야기해 볼까요? 그 아 우리...   \n",
            "\n",
            "  emotion  confidence  has_keyword  is_deepfake  \n",
            "0     NaN         NaN            1            0  \n",
            "1     NaN         NaN            0            0  \n",
            "2     NaN         NaN            1            0  \n",
            "3     NaN         NaN            1            0  \n",
            "4     NaN         NaN            1            0  \n",
            "✅ merged_normal 저장 완료 → /content/drive/MyDrive/merged_normal.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "### ================================\n",
        "### 1. 정상 데이터 json 폴더 경로\n",
        "### ================================\n",
        "normal_dir = \"/content/drive/MyDrive/NIKL_DIALOGUE_2024_JSON_FILT\"  # 폴더 경로 수정 필요\n",
        "\n",
        "# json 파일 목록\n",
        "json_files = [os.path.join(normal_dir, fname) for fname in os.listdir(normal_dir) if fname.endswith('.json')]\n",
        "\n",
        "print(f\"✅ json 파일 {len(json_files)}개 발견\")\n",
        "\n",
        "### ================================\n",
        "### 2. json → transcribed_text 추출\n",
        "### ================================\n",
        "normal_texts = []\n",
        "file_names = []\n",
        "\n",
        "for file_path in json_files:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "        utterances = []\n",
        "        for doc in data.get('document', []):\n",
        "            for utt in doc.get('utterance', []):\n",
        "                utterances.append(utt.get('form', ''))\n",
        "        # 각 파일에서 나온 모든 utterance → 하나의 text로 합치기\n",
        "        text_concat = \" \".join(utterances)\n",
        "        normal_texts.append(text_concat)\n",
        "        file_names.append(os.path.basename(file_path))\n",
        "\n",
        "### ================================\n",
        "### 3. DataFrame 생성\n",
        "### ================================\n",
        "normal_df = pd.DataFrame({\n",
        "    'file': file_names,\n",
        "    'transcribed_text': normal_texts\n",
        "})\n",
        "\n",
        "print(f\"✅ 정상 데이터 DataFrame 생성 완료: {normal_df.shape[0]} rows\")\n",
        "print(normal_df.head())\n",
        "\n",
        "### ================================\n",
        "### 4. keyword flag 추가 (같은 keyword 리스트 사용)\n",
        "### ================================\n",
        "custom_keywords = [\n",
        "    '통장', '고객', '은행', '계좌', '금융',\n",
        "    '카드', '조사', '대출', '피해자', '연락',\n",
        "    '자금', '피해', '수사', '진술', '불법'\n",
        "]\n",
        "\n",
        "def has_keyword(text):\n",
        "    return int(any(keyword in text for keyword in custom_keywords))\n",
        "\n",
        "normal_df['has_keyword'] = normal_df['transcribed_text'].apply(has_keyword)\n",
        "\n",
        "print(\"✅ keyword flag 추가 완료\")\n",
        "print(normal_df[['file', 'transcribed_text', 'has_keyword']].head())\n",
        "\n",
        "### ================================\n",
        "### 5. 감정분석 결과 merge\n",
        "### ================================\n",
        "emotion_df = pd.read_csv(\"/content/drive/MyDrive/emotion_results.csv\")\n",
        "\n",
        "merged_normal = pd.merge(normal_df, emotion_df, on='file', how='left')\n",
        "\n",
        "print(\"✅ 감정분석 merge 완료\")\n",
        "print(merged_normal[['file', 'transcribed_text', 'emotion', 'confidence', 'has_keyword']].head())\n",
        "\n",
        "### ================================\n",
        "### 6. is_deepfake 컬럼 추가\n",
        "### ================================\n",
        "merged_normal['is_deepfake'] = 0\n",
        "\n",
        "print(\"✅ is_deepfake 컬럼 추가 완료\")\n",
        "print(merged_normal[['file', 'transcribed_text', 'emotion', 'confidence', 'has_keyword', 'is_deepfake']].head())\n",
        "\n",
        "### ================================\n",
        "### 7. 저장\n",
        "### ================================\n",
        "merged_normal.to_csv(\"/content/drive/MyDrive/merged_normal.csv\", index=False)\n",
        "\n",
        "print(\"✅ merged_normal 저장 완료 → /content/drive/MyDrive/merged_normal.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87zbHu1OVxbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
